# Normalizing Flows Implementation

Ce projet est une implÃ©mentation interactive de diffÃ©rents modÃ¨les de Normalizing Flows (Flux Normalisants) avec une interface utilisateur Streamlit. Il permet de visualiser et d'expÃ©rimenter avec les transformations probabilistes NICE, RealNVP et Glow sur diffÃ©rentes distributions de donnÃ©es.

## ğŸ“‹ Table des MatiÃ¨res

- [Introduction](#introduction)
- [ModÃ¨les ImplÃ©mentÃ©s](#modÃ¨les-implÃ©mentÃ©s)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du Projet](#structure-du-projet)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Aspects Techniques](#aspects-techniques)
- [Contributions](#contributions)
- [RÃ©fÃ©rences](#rÃ©fÃ©rences)

## ğŸ” Introduction

Les Normalizing Flows sont des modÃ¨les gÃ©nÃ©ratifs qui apprennent Ã  transformer une distribution simple (comme une gaussienne) en une distribution complexe Ã  travers une sÃ©quence de transformations inversibles. Ce projet offre une interface interactive pour explorer ces modÃ¨les, comprendre leur fonctionnement et visualiser leurs transformations.

## ğŸ§  ModÃ¨les ImplÃ©mentÃ©s

### NICE (Non-linear Independent Components Estimation)
- Utilise des couplages additifs pour transformer les distributions
- Architecture simplifiÃ©e avec des transformations inversibles explicites
- ImplÃ©mentation basÃ©e sur l'article ["NICE: Non-linear Independent Components Estimation"](https://arxiv.org/abs/1410.8516)

### RealNVP (Real-valued Non-Volume Preserving)
- Extension de NICE avec des transformations affines (multiplication et addition)
- Permet des mappings plus expressifs grÃ¢ce aux changements d'Ã©chelle
- BasÃ© sur l'article ["Density Estimation using Real NVP"](https://arxiv.org/abs/1605.08803)

### Glow
- Architecture avancÃ©e combinant convolutions 1x1 inversibles et couplages affines
- Inclut une normalisation par lots et des rÃ©seaux plus profonds
- ImplÃ©mentation selon l'article ["Glow: Generative Flow with Invertible 1x1 Convolutions"](https://arxiv.org/abs/1807.03039)

## ğŸ’» Installation

```bash
# Cloner le repository
git clone https://github.com/EpsilonOF/ProjetDL.git
cd ProjetDL

# CrÃ©er et activer un environnement virtuel (optionnel)
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸš€ Utilisation

Pour lancer l'application Streamlit:

```bash
streamlit run app.py
```

L'interface web devrait s'ouvrir automatiquement dans votre navigateur, vous permettant de:
- SÃ©lectionner un modÃ¨le (NICE, RealNVP, Glow)
- Choisir une distribution de donnÃ©es (Cercles, Spirale, Gaussiennes multiples, etc.)
- Ajuster les hyperparamÃ¨tres d'entraÃ®nement
- Visualiser les transformations en temps rÃ©el

## ğŸ“ Structure du Projet

```
ProjetDL/
â”œâ”€â”€ app.py                  # Point d'entrÃ©e de l'application Streamlit
â”œâ”€â”€ requirements.txt        # DÃ©pendances du projet
â”œâ”€â”€ presentation.py         # PrÃ©sentation du sujet
â”œâ”€â”€ nice/                   # ImplÃ©mentation du modÃ¨le NICE
â”‚   â”œâ”€â”€ nice.py             # Mise en page du modÃ¨le
â”‚   â”œâ”€â”€ train_nice.py       # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ images/             # Si besoin d'enregistrer des images
â”œâ”€â”€ realnvp/                # ImplÃ©mentation du modÃ¨le RealNVP
â”‚   â”œâ”€â”€ real_nvp.py         # Mise en page du modÃ¨le
â”‚   â”œâ”€â”€ train_realnvp.py    # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ images/             # Si besoin d'enregistrer des images
â”œâ”€â”€ glow/                   # ImplÃ©mentation du modÃ¨le Glow
â”‚   â”œâ”€â”€ glow.py             # Mise en page du modÃ¨le
â”‚   â”œâ”€â”€ train_glow.py       # EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ images/             # Si besoin d'enregistrer des images
```

## âœ¨ FonctionnalitÃ©s

- **Visualisation en temps rÃ©el**: Observez comment la distribution se transforme pendant l'entraÃ®nement
- **Personnalisation des hyperparamÃ¨tres**: Ajustez le taux d'apprentissage, la taille des lots, le nombre d'epochs, etc.
- **Analyse comparative**: Comparez les performances des diffÃ©rents modÃ¨les sur les mÃªmes donnÃ©es

## ğŸ”§ Aspects Techniques

### Architecture des modÃ¨les

Les modÃ¨les sont implÃ©mentÃ©s comme des modules PyTorch hÃ©ritant d'une classe de base commune, ce qui permet une interface cohÃ©rente pour:
- La transformation directe (forward) d'une distribution simple en distribution complexe
- La transformation inverse (backward) pour gÃ©nÃ©rer de nouveaux Ã©chantillons
- Le calcul du log-dÃ©terminant jacobien pour l'estimation de densitÃ©

### EntraÃ®nement

L'entraÃ®nement utilise la maximisation de la vraisemblance (maximum likelihood estimation) comme objectif:
- Minimiser la divergence KL entre la distribution cible et la distribution transformÃ©e
- Optimisation par descente de gradient stochastique avec Adam
- Suivi des mÃ©triques d'entraÃ®nement comme la log-vraisemblance nÃ©gative

## ğŸ¤ Contributions

Les contributions sont les bienvenues! Pour contribuer:
1. Forkez le repository
2. CrÃ©ez une branche pour votre fonctionnalitÃ© (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Committez vos changements (`git commit -m 'Ajout d'une nouvelle fonctionnalitÃ©'`)
4. Poussez vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

## ğŸ“š RÃ©fÃ©rences

- [NICE: Non-linear Independent Components Estimation](https://arxiv.org/abs/1410.8516)
- [Density Estimation using Real NVP](https://arxiv.org/abs/1605.08803)
- [Glow: Generative Flow with Invertible 1x1 Convolutions](https://arxiv.org/abs/1807.03039)
