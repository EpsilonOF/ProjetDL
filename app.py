import streamlit as st

def main():
    # Configuration de la page
    st.set_page_config(
        page_title="Normalizing Flows",
        page_icon="üîÑ",
        layout="wide"
    )
    
    # Sidebar pour la navigation
    st.sidebar.title("Navigation")
    page = st.sidebar.radio(
        "Aller √†:",
        ["Pr√©sentation", "NICE", "RealNVP", "Glow"]
    )
    
    # Affichage des pages en fonction de la s√©lection
    if page == "Pr√©sentation":
        show_presentation()
    elif page == "NICE":
        show_nice()
    elif page == "RealNVP":
        show_realnvp()
    elif page == "Glow":
        show_glow()

def show_presentation():
    st.title("Les Normalizing Flows")
    
    st.header("Introduction")
    st.write("""
    Les normalizing flows sont une famille de mod√®les g√©n√©ratifs qui permettent 
    de transformer une distribution simple (comme une gaussienne) en une distribution 
    complexe via une s√©rie de transformations inversibles.
    """)
    
    st.header("Principe")
    st.write("""
    Le concept principal des normalizing flows repose sur le th√©or√®me de changement 
    de variable. √âtant donn√© une variable al√©atoire z avec une densit√© de probabilit√© 
    connue p(z) et une fonction bijective f, la densit√© de la variable transform√©e 
    x = f(z) peut √™tre calcul√©e comme:
    
    p(x) = p(z) | det(‚àÇf/‚àÇz)^(-1) |
    
    o√π ‚àÇf/‚àÇz est la jacobienne de la transformation f.
    """)
    
    st.header("Caract√©ristiques principales")
    st.write("""
    - **Inversibilit√©**: les transformations doivent √™tre bijectives
    - **Calcul efficace**: le d√©terminant de la jacobienne doit √™tre calculable efficacement
    - **Expressivit√©**: capacit√© √† repr√©senter des distributions complexes
    """)
    
    st.header("Mod√®les pr√©sent√©s")
    st.write("""
    Dans cette application, nous allons explorer trois architectures importantes 
    de normalizing flows:
    - **NICE**: Non-linear Independent Components Estimation
    - **RealNVP**: Real-valued Non-Volume Preserving transformations
    - **Glow**: Generative Flow with Invertible 1x1 Convolutions
    
    Utilisez la barre lat√©rale pour naviguer entre ces diff√©rents mod√®les.
    """)

def show_nice():
    st.title("NICE: Non-linear Independent Components Estimation")
    st.write("""
    Le mod√®le NICE (Non-linear Independent Components Estimation) est l'un des premiers 
    normalizing flows propos√©s par Dinh et al. en 2014.
    """)
    
    st.header("Principe")
    st.write("""
    NICE propose des transformations additives par blocs qui sont facilement inversibles.
    """)
    
    # Placeholder pour le contenu d√©taill√©
    st.info("Cette section sera enrichie avec plus de d√©tails sur le mod√®le NICE.")

def show_realnvp():
    st.title("RealNVP: Real-valued Non-Volume Preserving")
    st.write("""
    RealNVP (Real-valued Non-Volume Preserving) est une extension de NICE 
    propos√©e par Dinh et al. en 2016.
    """)
    
    st.header("Principe")
    st.write("""
    RealNVP introduit des transformations affines par blocs (multiplication et addition)
    ce qui rend le mod√®le plus expressif que NICE.
    """)
    
    # Placeholder pour le contenu d√©taill√©
    st.info("Cette section sera enrichie avec plus de d√©tails sur le mod√®le RealNVP.")

def show_glow():
    st.title("Glow: Generative Flow with Invertible 1x1 Convolutions")
    st.write("""
    Glow √©tend les concepts de RealNVP avec des convolutions inversibles
    et a √©t√© propos√© par Kingma et Dhariwal en 2018.
    """)
    
    st.header("Principe")
    st.write("""
    Glow ajoute des convolutions 1x1 inversibles pour permettre une meilleure 
    permutation des dimensions, ce qui est particuli√®rement utile pour les donn√©es d'images.
    
    L'architecture Glow est compos√©e de plusieurs blocs ayant chacun trois composantes principales:
    1. **Actnorm** - Normalisation par activation (g√©n√©ralisation de batch normalization)
    2. **Convolution 1x1 inversible** - Remplace l'√©tape de permutation utilis√©e dans RealNVP
    3. **Couplage affine** - Similaire √† RealNVP mais avec une architecture am√©lior√©e
    """)
    
    st.header("Composantes cl√©s")
    
    st.subheader("1. Actnorm")
    st.write("""
    L'Actnorm (Activation Normalization) est une couche de normalisation par canaux similaire √† 
    la batch normalization, mais avec des param√®tres d'√©chelle et de d√©calage appris par canal.
    
    Pour une entr√©e h, l'op√©ration est:
    ```
    y = s ‚äô (h + b)
    ```
    o√π s et b sont des param√®tres appris et ‚äô repr√©sente la multiplication √©l√©ment par √©l√©ment.
    
    Cette couche est initialis√©e pour que la sortie ait une moyenne nulle et une variance unitaire,
    ce qui aide √† stabiliser l'entra√Ænement des r√©seaux profonds.
    """)
    
    st.subheader("2. Convolution 1x1 inversible")
    st.write("""
    Les convolutions 1x1 inversibles remplacent les permutations fixes utilis√©es dans RealNVP
    par une op√©ration apprise. Cette op√©ration peut √™tre repr√©sent√©e par une matrice de poids W
    dont la taille est c√óc (o√π c est le nombre de canaux).
    
    Pour une entr√©e h, l'op√©ration est:
    ```
    y = Wh
    ```
    
    Le logarithme du d√©terminant de la jacobienne est simplement:
    ```
    log|det(‚àÇy/‚àÇh)| = log|det(W)|
    ```
    
    Le calcul na√Øf du d√©terminant aurait une complexit√© O(c¬≥), mais Glow utilise une 
    d√©composition LU pour r√©duire ce co√ªt √† O(c¬≤), rendant l'op√©ration efficace m√™me pour 
    un grand nombre de canaux.
    """)
    
    st.subheader("3. Couplage affine")
    st.write("""
    La couche de couplage affine dans Glow est similaire √† celle de RealNVP. Elle divise l'entr√©e
    en deux parties, applique une transformation √† une partie conditionn√©e sur l'autre:
    
    ```
    ha, hb = split(h)
    s, t = NN(ha)
    hb' = s ‚äô hb + t
    y = concat(ha, hb')
    ```
    
    o√π NN est un r√©seau de neurones. Contrairement √† RealNVP, Glow utilise des r√©seaux plus 
    sophistiqu√©s avec des convolutions, des normalisations et des activations non-lin√©aires.
    """)
    
    st.header("Architecture multi-√©chelle")
    st.write("""
    Glow utilise une architecture multi-√©chelle similaire √† RealNVP, o√π:
    
    1. L'image est trait√©e √† travers plusieurs √©tapes (steps of flow)
    2. √Ä certains points, la repr√©sentation est divis√©e en deux, avec une partie envoy√©e directement √† la sortie
    3. Ce processus permet de capturer les d√©pendances √† diff√©rentes √©chelles spatiales
    
    Cette conception hierarchique permet √† Glow de mod√©liser efficacement des images de haute r√©solution.
    """)
    
    st.header("Applications")
    st.write("""
    Glow a d√©montr√© d'excellentes performances dans plusieurs t√¢ches:
    
    1. **G√©n√©ration d'images** - Cr√©ation d'images photor√©alistes
    2. **Manipulation s√©mantique** - Modification d'attributs sp√©cifiques (sourire, lunettes, √¢ge, etc.)
    3. **Interpolation** - Transition fluide entre diff√©rentes images
    4. **Inpainting** - Compl√©tion de parties manquantes d'images
    """)
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Avantages")
        st.write("""
        - Estimation exacte de la log-vraisemblance
        - √âchantillonnage direct et rapide
        - Architecture inversible efficace
        - Manipulation pr√©cise d'attributs s√©mantiques
        """)
    
    with col2:
        st.subheader("Limitations")
        st.write("""
        - Complexit√© computationnelle √©lev√©e
        - N√©cessite beaucoup de m√©moire
        - Architecture moins flexible que les VAEs ou GANs
        - Difficult√© √† mod√©liser certaines distributions tr√®s complexes
        """)
    
    st.header("Formulation math√©matique")
    st.latex(r'''
    \log p_X(x) = \log p_Z(f(x)) + \log \left| \det \frac{\partial f(x)}{\partial x} \right|
    ''')
    
    st.write("""
    o√π:
    - $p_X(x)$ est la densit√© de probabilit√© des donn√©es r√©elles
    - $p_Z(z)$ est la densit√© de probabilit√© de la distribution latente (g√©n√©ralement une gaussienne)
    - $f$ est la transformation inversible apprise
    - Le second terme est le logarithme du d√©terminant de la jacobienne de la transformation
    """)
    
    st.header("Impl√©mentation et d√©mo interactive")
    st.write("""
    Vous pouvez exp√©rimenter avec le mod√®le Glow ci-dessous en ajustant diff√©rents param√®tres:
    """)

    # Disposition en colonnes pour les param√®tres et r√©sultats
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("Param√®tres du mod√®le")
        n_flow = st.slider("Nombre de couches de flux", min_value=1, max_value=32, value=12, step=1)
        n_blocks = st.slider("Nombre de blocs", min_value=1, max_value=8, value=4, step=1)
        no_lu = st.checkbox("D√©sactiver la d√©composition LU (plus lent mais potentiellement plus pr√©cis)", value=False)
        
        st.subheader("Param√®tres de g√©n√©ration")
        temperature = st.slider("Temp√©rature (contr√¥le la variabilit√©)", min_value=0.1, max_value=1.0, value=0.7, step=0.1)
        batch_size = st.slider("Nombre d'images √† g√©n√©rer", min_value=1, max_value=16, value=4, step=1)
        
        seed = st.number_input("Seed pour la g√©n√©ration al√©atoire", min_value=0, max_value=9999, value=42)
        
        generate_button = st.button("G√©n√©rer des images")

    with col2:
        st.subheader("Manipulation d'attributs")
        st.write("Ajustez les attributs s√©mantiques pour modifier les images g√©n√©r√©es:")
        
        sourire = st.slider("Sourire", min_value=-2.0, max_value=2.0, value=0.0, step=0.1)
        age = st.slider("√Çge", min_value=-2.0, max_value=2.0, value=0.0, step=0.1)
        lunettes = st.slider("Lunettes", min_value=-2.0, max_value=2.0, value=0.0, step=0.1)
        genre = st.slider("Genre", min_value=-2.0, max_value=2.0, value=0.0, step=0.1)
        
        attributs = {
            "Sourire": sourire,
            "√Çge": age,
            "Lunettes": lunettes,
            "Genre": genre
        }

    # Section pour afficher les r√©sultats
    st.subheader("R√©sultats de la g√©n√©ration")

    if generate_button:
        with st.spinner("G√©n√©ration d'images en cours..."):
            # Dans une impl√©mentation r√©elle, vous appelleriez ici votre mod√®le
            # Simulons un d√©lai pour l'effet
            import time
            time.sleep(2)
            
            # Affichage des r√©sultats (simulations avec des placeholders)
            st.write(f"Images g√©n√©r√©es avec temp√©rature={temperature}, attributs appliqu√©s:")
            
            # Cr√©er une grille d'images g√©n√©r√©es
            image_cols = st.columns(min(4, batch_size))
            for i in range(batch_size):
                col_idx = i % 4
                with image_cols[col_idx]:
                    # Dans une impl√©mentation r√©elle, vous afficheriez les vraies images g√©n√©r√©es
                    # Pour l'instant, utilisons des placeholders
                    st.image(f"https://via.placeholder.com/150?text=Glow+Image+{i+1}", 
                            caption=f"Image {i+1}")
                    
                    st.write(f"Param√®tres appliqu√©s:")
                    for attr, val in attributs.items():
                        if abs(val) > 0.1:  # N'afficher que les attributs significativement modifi√©s
                            st.write(f"- {attr}: {val:+.1f}")

    # Information sur l'utilisation
    st.info("""
    **Note**: Cette d√©mo est une simulation de l'interface utilisateur. Dans une impl√©mentation 
    compl√®te, elle serait connect√©e √† un mod√®le Glow pr√©-entra√Æn√©. Pour ex√©cuter r√©ellement 
    un mod√®le Glow, des ressources GPU importantes sont n√©cessaires en raison de la complexit√© 
    du mod√®le.
    """)

    # Explication suppl√©mentaire sur le fonctionnement de la manipulation
    st.header("Comment fonctionne la manipulation d'attributs")
    st.write("""
    La manipulation d'attributs dans Glow fonctionne gr√¢ce √† l'espace latent structur√©:

    1. Le mod√®le apprend √† transformer des donn√©es complexes en distribution gaussienne
    2. Dans cet espace latent, certaines directions correspondent √† des attributs s√©mantiques
    3. En modifiant les vecteurs dans l'espace latent selon ces directions, on peut 
    ajuster des caract√©ristiques sp√©cifiques
    4. La transformation inverse permet de g√©n√©rer de nouvelles images avec les attributs modifi√©s

    Cette approche permet une √©dition pr√©cise et contr√¥l√©e, contrairement aux GANs o√π 
    le contr√¥le pr√©cis est souvent plus difficile √† obtenir.
    """)
    st.header("Ressources")
    st.write("""
    Pour approfondir vos connaissances sur Glow:
    
    - [Article original: "Glow: Generative Flow with Invertible 1x1 Convolutions"](https://arxiv.org/abs/1807.03039)
    - [Code source officiel d'OpenAI](https://github.com/openai/glow)
    - [Tutoriel PyTorch sur l'impl√©mentation de Glow](https://github.com/rosinality/glow-pytorch)
    """)

if __name__ == "__main__":
    main()